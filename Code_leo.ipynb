{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### charger les docs csv\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "data_folder = './eleves/'\n",
    "csv_folder = os.path.join(data_folder, 'csv')\n",
    "sql_folder = os.path.join(data_folder, 'SQL')\n",
    "\n",
    "if not os.path.exists(sql_folder):\n",
    "    os.makedirs(sql_folder)\n",
    "\n",
    "csv_files = [f for f in os.listdir(csv_folder) if f.endswith('.csv')]\n",
    "\n",
    "for file in csv_files:\n",
    "    filename = os.path.join(csv_folder, file)\n",
    "    sqlite_filename = os.path.join(sql_folder, file[:-3] + \"sqlite3\")\n",
    "\n",
    "    con = sqlite3.connect(sqlite_filename)\n",
    "\n",
    "    if file == \"Sondage_LV2.csv\":\n",
    "        pd.read_csv(filename, encoding='latin1', usecols=['Nom','mail','Langues']).to_sql(file[:-4], con, if_exists='replace', index=False)\n",
    "    else:\n",
    "        pd.read_csv(filename, encoding='latin1', usecols=['Nom','Mail','Note/10']).to_sql(file[:-4], con, if_exists='replace', index=False)\n",
    "\n",
    "    con.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### charger les docs json\n",
    "\n",
    "je ne sais plus ce que fait le premier mais il faut utiliser le deuxième"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "\n",
    "data_folder = './eleves/'\n",
    "json_folder = os.path.join(data_folder, 'json')\n",
    "sql_folder = os.path.join(data_folder, 'SQL')\n",
    "\n",
    "if not os.path.exists(sql_folder):\n",
    "    os.makedirs(sql_folder)\n",
    "\n",
    "json_files = [f for f in os.listdir(json_folder) if f.endswith('.json')]\n",
    "\n",
    "for file in json_files:\n",
    "    filename = os.path.join(json_folder, file)\n",
    "    sqlite_filename = os.path.join(sql_folder, file[:-4] + \"sqlite3\")\n",
    "    con = sqlite3.connect(sqlite_filename)\n",
    "    with open(filename, 'r', encoding='utf-8-sig') as json_file:\n",
    "        data = json.load(json_file)\n",
    "        if file == \"Sondage_LV2.json\":\n",
    "            pd.DataFrame(data, columns=['Nom','Prénom','mail','Langues']).to_sql(file[:-5], con, if_exists='replace', index=False)\n",
    "        else:\n",
    "            pd.DataFrame(data, columns=['Nom','Prénom','mail','Note/10']).to_sql(file[:-5], con, if_exists='replace', index=False)\n",
    "\n",
    "    con.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "data_folder = './eleves/'\n",
    "json_folder = os.path.join(data_folder, 'json')\n",
    "sql_folder = os.path.join(data_folder, 'SQL')\n",
    "\n",
    "if not os.path.exists(sql_folder):\n",
    "    os.makedirs(sql_folder)\n",
    "\n",
    "db_path = os.path.join(sql_folder, 'data.sqlite3')\n",
    "conn = sqlite3.connect(db_path)\n",
    "\n",
    "json_files = [f for f in os.listdir(json_folder) if f.endswith('.json')]\n",
    "\n",
    "for file in json_files:\n",
    "    table_name = os.path.splitext(file)[0]\n",
    "    json_file_path = os.path.join(json_folder, file)\n",
    "\n",
    "    with open(json_file_path, 'r', encoding='utf-8-sig') as json_file:\n",
    "        data = json.load(json_file)\n",
    "        \n",
    "        if file == \"Sondage_LV2.json\":\n",
    "            df = pd.DataFrame(data, columns=['Nom','Prénom','mail','Langues'])\n",
    "        else:\n",
    "            df = pd.DataFrame(data, columns=['Nom','Prénom','mail','Note/10'])\n",
    "            df['Note/10'] = df['Note/10'].replace('', np.nan)\n",
    "            df['Note/10'] = df['Note/10'].astype(float)\n",
    "\n",
    "        df.to_sql(table_name, conn, if_exists='replace', index=False)\n",
    "conn.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### charger les docs xlsx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "data_folder = './eleves/'\n",
    "xlsx_folder = os.path.join(data_folder, 'xlsx')\n",
    "sql_folder = os.path.join(data_folder, 'SQL')\n",
    "\n",
    "if not os.path.exists(sql_folder):\n",
    "    os.makedirs(sql_folder)\n",
    "\n",
    "xlsx_files = [f for f in os.listdir(xlsx_folder) if f.endswith('.xlsx')]\n",
    "\n",
    "for file in xlsx_files:\n",
    "    filename = os.path.join(xlsx_folder, file)\n",
    "    sqlite_filename = os.path.join(sql_folder, file[:-4] + \"sqlite3\")\n",
    "\n",
    "    con = sqlite3.connect(sqlite_filename)\n",
    "\n",
    "    if file == \"Sondage_LV2.xlsx\":\n",
    "        pd.read_excel(filename, usecols=['Nom','Prénom','mail','Langues']).to_sql(file[:-5], con, if_exists='replace', index=False)\n",
    "    else:\n",
    "        pd.read_excel(filename, usecols=['Nom','Prénom','Mail','Note/10']).to_sql(file[:-5], con, if_exists='replace', index=False)\n",
    "\n",
    "    con.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find table names\n",
    "\n",
    "entry: chemin de la database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tables in the database: ['Anglais', 'Espagnol', 'Sondage_LV2', 'General']\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "\n",
    "def list_tables(filename):\n",
    "    conn = sqlite3.connect(filename)\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n",
    "    tables = cursor.fetchall()\n",
    "    conn.close()\n",
    "    return [table[0] for table in tables]\n",
    "\n",
    "Data = 'eleves/SQL/data.sqlite3'\n",
    "print(\"Tables in the database:\", list_tables(Data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delete table\n",
    "\n",
    "!!!! attention c'est définitif !!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "\n",
    "Data = 'eleves/SQL/data.sqlite3'\n",
    "def Delete_all_tables(filename):\n",
    "    for i in list_tables(filename):\n",
    "        conn = sqlite3.connect(filename)\n",
    "        cursor = conn.cursor()\n",
    "        if i != 'General':\n",
    "            cursor.execute(\"DROP TABLE \" + i + \";\")\n",
    "        tables = cursor.fetchall()\n",
    "        conn.close()\n",
    "    return\n",
    "\n",
    "#Delete_all_tables(Data)\n",
    "\n",
    "def Delete_one_table(filename, name_table):\n",
    "    conn = sqlite3.connect(filename)\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute(\"DROP TABLE \" + name_table + \";\")\n",
    "    tables = cursor.fetchall()\n",
    "    conn.close()\n",
    "    return\n",
    "\n",
    "#Delete_one_table(Data, \"Allemand\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create one general table \n",
    "\n",
    "entry: chemin de la database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tables in the database: []\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "\n",
    "def Create_tables(filename):\n",
    "    conn = sqlite3.connect(filename)\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute(\"CREATE TABLE General (NAME VARCHAR(50),SURNAME VARCHAR(50),EMAIL VARCHAR(50),CLASS VARCHAR(5),LV1 VARCHAR(50),GRADE_LV1 INT,GROUP_LV1 INT,LV2 VARCHAR(50),GRADE_LV2 INT,GROUP_LV2 VARCHAR(50));\")\n",
    "    tables = cursor.fetchall()\n",
    "    conn.close()\n",
    "    return [table[0] for table in tables]\n",
    "\n",
    "Data = 'eleves/SQL/data.sqlite3'\n",
    "print(\"Tables in the database:\", Create_tables(Data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### file general table "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "\n",
    "def Create_tables(filename):\n",
    "    conn = sqlite3.connect(filename)\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute(\"INSERT INTO General (NAME, colonne2, ..., colonneN) SELECT colonne_a_copier1, colonne_a_copier2, ..., colonne_a_copierN FROM Sondage_LV2;\")\n",
    "    tables = cursor.fetchall()\n",
    "    conn.close()\n",
    "    return [table[0] for table in tables]\n",
    "\n",
    "Data = 'eleves/SQL/data.sqlite3'\n",
    "#print(\"Tables in the database:\", Create_tables(Data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### add forecast\n",
    "\n",
    "entry: nb of forecast, database, table(subject), mu, sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30 forecast add []\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "import numpy as np\n",
    "\n",
    "forecast = 30\n",
    "Data = 'eleves/SQL/data.sqlite3'\n",
    "table= 'Anglais'\n",
    "\n",
    "\n",
    "mu_ANG = 6.68\n",
    "sigma_ANG = 1.9\n",
    "mu_ESP = 6.38\n",
    "sigma_ESP = 1.69\n",
    "\n",
    "\n",
    "def add_forcast(filename,table_add, nb_forecast, mu , sigma ):\n",
    "    for i in range(0,nb_forecast):\n",
    "        conn = sqlite3.connect(filename)\n",
    "        cursor = conn.cursor()\n",
    "        valeur_gaussienne = str(np.random.uniform(0, 10))\n",
    "        cursor.execute(\"INSERT INTO \" + table_add + \" ('Nom', 'Prénom', 'mail', 'Note/10' ) VALUES ('forecast', 'forecast', 'forecast','\" + valeur_gaussienne + \"')\")\n",
    "        group = cursor.fetchall()\n",
    "        conn.commit()\n",
    "        conn.close()\n",
    "    return group \n",
    "\n",
    "print(forecast,\"forecast add\", add_forcast(Data,table,forecast,mu_ANG, sigma_ANG ))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create groups\n",
    "\n",
    "entry: database, table (subject), nb by class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "\n",
    "def extract_group(filename, table_add):\n",
    "    conn = sqlite3.connect(filename)\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute(\"SELECT * FROM \" + table_add + \" ORDER BY [Note/10] DESC\")\n",
    "    group = cursor.fetchall()\n",
    "    conn.close()\n",
    "    return group\n",
    "\n",
    "\n",
    "Data = 'eleves/SQL/data.sqlite3'\n",
    "table= 'Anglais'\n",
    "group_data = extract_group(Data, table)\n",
    "\n",
    "\n",
    "def nomber_class(nomber_student, nomber_by_class):\n",
    "    nomber_class = 0\n",
    "    if (nomber_student % nomber_by_class) > ((nomber_student //nomber_by_class)*(2/3)) :\n",
    "        nomber_class = nomber_student//nomber_by_class + 1\n",
    "    else :\n",
    "        nomber_class = nomber_student//nomber_by_class\n",
    "    return nomber_class\n",
    "\n",
    "nb_student = len(group_data)\n",
    "nb_by_class = 16\n",
    "nb_class = nomber_class(nb_student,nb_by_class)\n",
    "\n",
    "\n",
    "def groups(list_student, number_class):\n",
    "    \n",
    "    # Step 2: Divide the sorted list of students into groups\n",
    "    total_students = len(list_student)\n",
    "    students_per_group = total_students // number_class\n",
    "    groups = []\n",
    "    start_idx = 0\n",
    "    for i in range(number_class):\n",
    "        end_idx = start_idx + students_per_group\n",
    "        if i < total_students % number_class:  # If there are remaining students, distribute them\n",
    "            end_idx += 1\n",
    "        groups.append(list_student[start_idx:end_idx])\n",
    "        start_idx = end_idx\n",
    "    \n",
    "    return groups\n",
    "\n",
    "groups = groups(group_data, nb_class)\n",
    "#print(groups)\n",
    "\n",
    "\n",
    "#for group in groups:\n",
    "    #print('\\nGroupe\\n', len(group), \"\\n\", group)\n",
    "    #mean = 0\n",
    "    #for student in group:\n",
    "        #mean =+ mean + float(student[3])\n",
    "    #print(len(group))\n",
    "    #print('Mean', mean/len(group))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### export the group in PDF \n",
    "\n",
    "entry : liste des groupes + matière du groupe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "from reportlab.lib.pagesizes import letter\n",
    "from reportlab.platypus import SimpleDocTemplate, Paragraph, Table, TableStyle, Spacer\n",
    "from reportlab.lib import colors\n",
    "from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle\n",
    "from reportlab.lib.enums import TA_CENTER\n",
    "import os\n",
    "\n",
    "\n",
    "def pdf_maker(groups, langage):\n",
    "    i = 1\n",
    "    styles = getSampleStyleSheet()  \n",
    "\n",
    "    for group in groups:\n",
    "        pdf_path = f\"eleves/pdf/{langage}_Group_{i}.pdf\"\n",
    "        if os.path.exists(pdf_path):\n",
    "            os.remove(pdf_path)\n",
    "\n",
    "        doc = SimpleDocTemplate(pdf_path, pagesize=letter)\n",
    "        content = []\n",
    "\n",
    "        title = Paragraph(f\"<b>{langage}: Group {i}</b>\", styles[\"Title\"])\n",
    "        content.append(title)\n",
    "        content.append(Spacer(1, 12))  \n",
    "\n",
    "        data = group\n",
    "        table_data = [(\"Name\", \"Surname\", \"Email\", \"Mark\")]\n",
    "        table_data.extend(data)  \n",
    "\n",
    "        table = Table(table_data)\n",
    "        style = TableStyle([('BACKGROUND', (0,0), (-1,0), colors.grey),\n",
    "                            ('TEXTCOLOR', (0,0), (-1,0), colors.whitesmoke),\n",
    "                            ('ALIGN', (0,0), (-1,-1), 'CENTER'),\n",
    "                            ('FONTNAME', (0,0), (-1,0), 'Helvetica-Bold'),\n",
    "                            ('BOTTOMPADDING', (0,0), (-1,0), 12),\n",
    "                            ('BACKGROUND', (0,1), (-1,-1), colors.beige),\n",
    "                            ('GRID', (0,0), (-1,-1), 1, colors.black)])\n",
    "        table.setStyle(style)\n",
    "\n",
    "        content.append(table)\n",
    "\n",
    "        content.append(Spacer(1, 12)) \n",
    "        centered_style = ParagraphStyle(name='Centered', parent=styles['Normal'], alignment=TA_CENTER)\n",
    "\n",
    "        marks = [member[-1] for member in group]  # Supposer que la note est le dernier élément de chaque tuple\n",
    "        mean_mark = sum(marks) / len(marks) if marks else 0\n",
    "\n",
    "        summary = Paragraph(f\"Number of student: {len(group)} ; Mark mean: {mean_mark:.2f}\", centered_style)\n",
    "        content.append(summary)\n",
    "        doc.build(content)\n",
    "        #print(f\"Le fichier PDF '{pdf_path}' a été créé avec succès.\")\n",
    "        i += 1\n",
    "\n",
    "\n",
    "pdf_maker(groups, \"Anglais\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
