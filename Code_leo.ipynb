{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### charger les docs csv\n",
    "\n",
    "attention bug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "data_folder = './data/'\n",
    "csv_folder = os.path.join(data_folder, 'csv')\n",
    "sql_folder = os.path.join(data_folder, 'SQL')\n",
    "\n",
    "if not os.path.exists(sql_folder):\n",
    "    os.makedirs(sql_folder)\n",
    "\n",
    "csv_files = [f for f in os.listdir(csv_folder) if f.endswith('.csv')]\n",
    "\n",
    "for file in csv_files:\n",
    "    filename = os.path.join(csv_folder, file)\n",
    "    sqlite_filename = os.path.join(sql_folder, file[:-3] + \"sqlite3\")\n",
    "\n",
    "    con = sqlite3.connect(sqlite_filename)\n",
    "\n",
    "    if file == \"Sondage_LV2.csv\":\n",
    "        pd.read_csv(filename, encoding='latin1', usecols=['Nom','mail','Langues']).to_sql(file[:-4], con, if_exists='replace', index=False)\n",
    "    else:\n",
    "        pd.read_csv(filename, encoding='latin1', usecols=['Nom','Mail','Note/10']).to_sql(file[:-4], con, if_exists='replace', index=False)\n",
    "\n",
    "    con.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import json\n",
    "\n",
    "# Chemin vers le fichier CSV d'entrée\n",
    "input_csv = \"data/data_students/Info_student.csv\"\n",
    "\n",
    "# Chemin vers le fichier JSON de sortie\n",
    "output_json = \"data/data_students/Info_student.json\"\n",
    "\n",
    "# Fonction pour lire le fichier CSV et le convertir en JSON\n",
    "def csv_to_json(csv_file, json_file):\n",
    "    # Ouvrir le fichier CSV en mode lecture\n",
    "    with open(csv_file, \"r\", newline=\"\") as file:\n",
    "        # Lire le contenu du fichier CSV\n",
    "        csv_data = csv.DictReader(file)\n",
    "        # Convertir les données du CSV en une liste de dictionnaires\n",
    "        data_list = [row for row in csv_data]\n",
    "    \n",
    "    # Convertir la liste de dictionnaires en JSON\n",
    "    json_data = json.dumps(data_list, indent=4)\n",
    "    \n",
    "    # Écrire le JSON dans un fichier\n",
    "    with open(json_file, \"w\") as json_file:\n",
    "        json_file.write(json_data)\n",
    "\n",
    "# Appel de la fonction pour effectuer la conversion\n",
    "csv_to_json(input_csv, output_json)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### charger les docs json\n",
    "\n",
    "je ne sais plus ce que fait le premier mais il faut utiliser le deuxième"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "\n",
    "data_folder = './data/'\n",
    "json_folder = os.path.join(data_folder, 'json')\n",
    "sql_folder = os.path.join(data_folder, 'SQL')\n",
    "\n",
    "if not os.path.exists(sql_folder):\n",
    "    os.makedirs(sql_folder)\n",
    "\n",
    "json_files = [f for f in os.listdir(json_folder) if f.endswith('.json')]\n",
    "\n",
    "for file in json_files:\n",
    "    filename = os.path.join(json_folder, file)\n",
    "    sqlite_filename = os.path.join(sql_folder, file[:-4] + \"sqlite3\")\n",
    "    con = sqlite3.connect(sqlite_filename)\n",
    "    with open(filename, 'r', encoding='utf-8-sig') as json_file:\n",
    "        data = json.load(json_file)\n",
    "        if file == \"Sondage_LV2.json\":\n",
    "            pd.DataFrame(data, columns=['Nom','Prénom','mail','Langues']).to_sql(file[:-5], con, if_exists='replace', index=False)\n",
    "        else:\n",
    "            pd.DataFrame(data, columns=['Nom','Prénom','mail','Note/10']).to_sql(file[:-5], con, if_exists='replace', index=False)\n",
    "\n",
    "    con.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "data_folder = './data/'\n",
    "json_folder = os.path.join(data_folder, 'json')\n",
    "sql_folder = os.path.join(data_folder, 'SQL')\n",
    "\n",
    "if not os.path.exists(sql_folder):\n",
    "    os.makedirs(sql_folder)\n",
    "\n",
    "db_path = os.path.join(sql_folder, 'data_brute.sqlite3')\n",
    "conn = sqlite3.connect(db_path)\n",
    "\n",
    "json_files = [f for f in os.listdir(json_folder) if f.endswith('.json')]\n",
    "\n",
    "for file in json_files:\n",
    "    table_name = os.path.splitext(file)[0]\n",
    "    json_file_path = os.path.join(json_folder, file)\n",
    "\n",
    "    with open(json_file_path, 'r', encoding='utf-8-sig') as json_file:\n",
    "        data = json.load(json_file)\n",
    "        \n",
    "        if file == \"Sondage_LV2.json\":\n",
    "            df = pd.DataFrame(data, columns=['Nom','Prénom','mail','Langues'])\n",
    "        else:\n",
    "            df = pd.DataFrame(data, columns=['Nom','Prénom','mail','Note/10'])\n",
    "            df['Note/10'] = df['Note/10'].replace('', np.nan)\n",
    "            df['Note/10'] = df['Note/10'].astype(float)\n",
    "\n",
    "        df.to_sql(table_name, conn, if_exists='replace', index=False)\n",
    "conn.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "data_folder = './data/'\n",
    "json_folder = os.path.join(data_folder, 'data')\n",
    "sql_folder = os.path.join(data_folder, 'SQL')\n",
    "\n",
    "if not os.path.exists(sql_folder):\n",
    "    os.makedirs(sql_folder)\n",
    "\n",
    "db_path = os.path.join(sql_folder, 'data.sqlite3')\n",
    "conn = sqlite3.connect(db_path)\n",
    "\n",
    "json_files = [f for f in os.listdir(json_folder) if f.endswith('.json')]\n",
    "\n",
    "for file in json_files:\n",
    "    table_name = os.path.splitext(file)[0]\n",
    "    json_file_path = os.path.join(json_folder, file)\n",
    "\n",
    "    with open(json_file_path, 'r', encoding='utf-8-sig') as json_file:\n",
    "        data = json.load(json_file)\n",
    "        df = pd.DataFrame(data, columns=['Nom','Prénom','mail','Class'])\n",
    "        df.to_sql(table_name, conn, if_exists='replace', index=False)\n",
    "conn.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "\n",
    "data_folder = './data/'\n",
    "json_folder = os.path.join(data_folder, 'data_students')\n",
    "sql_folder = os.path.join(data_folder, 'SQL')\n",
    "chemin_fichier_json = './data/json/Sondage_LV2.json'\n",
    "\n",
    "\n",
    "def file_General_table(json_folder, sql_folder):\n",
    "    if not os.path.exists(sql_folder):\n",
    "        os.makedirs(sql_folder)\n",
    "\n",
    "    json_to_db_column_mapping = {\n",
    "    'Nom': 'NAME',\n",
    "    'Prénom': 'SURNAME',\n",
    "    'mail': 'EMAIL',\n",
    "    'Class': 'CLASS' \n",
    "    }\n",
    "\n",
    "    db_path = os.path.join(sql_folder, 'data.sqlite3')\n",
    "    conn = sqlite3.connect(db_path)\n",
    "\n",
    "    json_files = [f for f in os.listdir(json_folder) if f.endswith('.json')]\n",
    "    desired_table_name = 'General'\n",
    "\n",
    "    for file in json_files:\n",
    "        json_file_path = os.path.join(json_folder, file)\n",
    "\n",
    "        with open(json_file_path, 'r', encoding='utf-8-sig') as json_file:\n",
    "            data = json.load(json_file)\n",
    "\n",
    "            # Transform the data based on the defined mapping\n",
    "            transformed_data = []\n",
    "            for item in data:\n",
    "                transformed_item = {db_column: item.get(json_field) for json_field, db_column in json_to_db_column_mapping.items()}\n",
    "                transformed_data.append(transformed_item)\n",
    "\n",
    "            df = pd.DataFrame(transformed_data)\n",
    "            df.to_sql(desired_table_name, conn, if_exists='append', index=False)\n",
    "\n",
    "    conn.close()\n",
    "    return\n",
    "\n",
    "def complete_General_table_lv2(sql_folder, chemin_fichier_json):\n",
    "    with open(chemin_fichier_json, 'r', encoding='utf-8-sig') as fichier:\n",
    "        donnees = json.load(fichier)\n",
    "        db_path = os.path.join(sql_folder, 'data.sqlite3')\n",
    "        conn_destination = sqlite3.connect(db_path)\n",
    "        cursor_destination = conn_destination.cursor()\n",
    "\n",
    "        for ligne in donnees:\n",
    "\n",
    "            #print(ligne[\"Nom\"], ligne[\"Prénom\"], ligne[\"mail\"], ligne[\"Langues\"] )\n",
    "            cursor_destination.execute(\"SELECT COUNT(*) FROM General WHERE (NAME = ? AND SURNAME = ?) OR EMAIL = ?;\", (ligne[\"Nom\"], ligne[\"Prénom\"], ligne[\"mail\"]))\n",
    "            count = cursor_destination.fetchone()[0]\n",
    "            \n",
    "            if count == 0:\n",
    "                print(ligne, \"doesn't exist\")\n",
    "            else :\n",
    "                cursor_destination.execute(\"UPDATE General SET LV2=?, STATUS=? WHERE (NAME = ? AND SURNAME = ?) OR EMAIL = ? ;\", (ligne[\"Langues\"],\"PRESENT\",ligne[\"Nom\"], ligne[\"Prénom\"], ligne[\"mail\"]))\n",
    "\n",
    "        conn_destination.commit()\n",
    "        conn_destination.close()\n",
    "\n",
    "\n",
    "file_General_table(json_folder, sql_folder)\n",
    "complete_General_table_lv2(sql_folder, chemin_fichier_json)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### charger les docs xlsx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "data_folder = './data/'\n",
    "xlsx_folder = os.path.join(data_folder, 'xlsx')\n",
    "sql_folder = os.path.join(data_folder, 'SQL')\n",
    "\n",
    "if not os.path.exists(sql_folder):\n",
    "    os.makedirs(sql_folder)\n",
    "\n",
    "xlsx_files = [f for f in os.listdir(xlsx_folder) if f.endswith('.xlsx')]\n",
    "\n",
    "for file in xlsx_files:\n",
    "    filename = os.path.join(xlsx_folder, file)\n",
    "    sqlite_filename = os.path.join(sql_folder, file[:-4] + \"sqlite3\")\n",
    "\n",
    "    con = sqlite3.connect(sqlite_filename)\n",
    "\n",
    "    if file == \"Sondage_LV2.xlsx\":\n",
    "        pd.read_excel(filename, usecols=['Nom','Prénom','mail','Langues']).to_sql(file[:-5], con, if_exists='replace', index=False)\n",
    "    else:\n",
    "        pd.read_excel(filename, usecols=['Nom','Prénom','Mail','Note/10']).to_sql(file[:-5], con, if_exists='replace', index=False)\n",
    "\n",
    "    con.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Charge any file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "\n",
    "def load_survey(depot_note_folder,sql_folder,name_server_brute ):\n",
    "    if not os.path.exists(sql_folder):\n",
    "        os.makedirs(sql_folder)\n",
    "\n",
    "    db_path = os.path.join(sql_folder, name_server_brute)\n",
    "    conn = sqlite3.connect(db_path)\n",
    "\n",
    "    for file in [f for f in os.listdir(depot_note_folder)]:\n",
    "        file_path = os.path.join(depot_note_folder, file)\n",
    "        if file.endswith('.csv'):\n",
    "            filename = os.path.join(depot_note_folder, file)\n",
    "            if file == \"Sondage_LV2.csv\":\n",
    "                df = pd.read_csv(filename, encoding='utf8', usecols=['Nom','mail','Langues'])\n",
    "            else:\n",
    "                df = pd.read_csv(filename, encoding='utf8', usecols=['Nom','Mail','Note/10'])\n",
    "                df['Note/10'] = df['Note/10'].replace('', np.nan)\n",
    "                df['Note/10'] = df['Note/10'].astype(float)\n",
    "            df.to_sql(file[:-4], conn, if_exists='replace', index=False)\n",
    "            \n",
    "        elif file.endswith('.json'):\n",
    "            json_file_path = os.path.join(depot_note_folder, file)\n",
    "            with open(json_file_path, 'r', encoding='utf-8-sig') as json_file:\n",
    "                data = json.load(json_file)\n",
    "                if file == \"Sondage_LV2.json\":\n",
    "                    df = pd.DataFrame(data, columns=['Nom','Prénom','mail','Langues'])\n",
    "                else:\n",
    "                    df = pd.DataFrame(data, columns=['Nom','Prénom','mail','Note/10'])\n",
    "                    df['Note/10'] = df['Note/10'].replace('', np.nan)\n",
    "                    df['Note/10'] = df['Note/10'].astype(float)\n",
    "                df.to_sql(file[:-5], conn, if_exists='replace', index=False)\n",
    "            \n",
    "        elif file.endswith('.xlsx'):\n",
    "            filename = os.path.join(depot_note_folder, file)\n",
    "            if file == \"Sondage_LV2.xlsx\":\n",
    "                df = pd.read_excel(filename, usecols=['Nom','Prénom','mail','Langues'])\n",
    "            else :\n",
    "                df = pd.read_excel(filename, usecols=['Nom','Prénom','Mail','Note/10'])\n",
    "                df['Note/10'] = df['Note/10'].replace('', np.nan)\n",
    "                df['Note/10'] = df['Note/10'].astype(float)\n",
    "            df.to_sql(file[:-5], conn, if_exists='replace', index=False)\n",
    "        \n",
    "        else:\n",
    "            print(f\"Format de fichier non pris en charge: {file}\")\n",
    "\n",
    "    conn.close()\n",
    "    return\n",
    "\n",
    "\n",
    "\n",
    "data_folder = './data/'\n",
    "depot_note_folder = os.path.join(data_folder, 'depot')\n",
    "sql_folder = os.path.join(data_folder, 'SQL')\n",
    "name_server_brute = 'data_brute.sqlite3' \n",
    "\n",
    "load_survey(depot_note_folder,sql_folder,name_server_brute)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find table names\n",
    "\n",
    "entry: chemin de la database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tables in the database: ['General', 'Teachers', 'Availabilities', 'Rooms', 'Summary', 'Availability_Teachers', 'Availability_Rooms']\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "\n",
    "def list_tables(filename):\n",
    "    conn = sqlite3.connect(filename)\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n",
    "    tables = cursor.fetchall()\n",
    "    conn.close()\n",
    "    return [table[0] for table in tables]\n",
    "\n",
    "Data = 'data/SQL/data.sqlite3'\n",
    "print(\"Tables in the database:\", list_tables(Data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tables in the database: ['Anglais', 'Espagnol', 'Sondage_LV2', 'Allemand', 'Info_student']\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "\n",
    "def list_tables(filename):\n",
    "    conn = sqlite3.connect(filename)\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n",
    "    tables = cursor.fetchall()\n",
    "    conn.close()\n",
    "    return [table[0] for table in tables]\n",
    "\n",
    "Data = 'data/SQL/data_brute.sqlite3'\n",
    "print(\"Tables in the database:\", list_tables(Data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delete table\n",
    "\n",
    "!!!! attention c'est définitif !!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "\n",
    "Data_brute = 'data/SQL/data_brute.sqlite3'\n",
    "def Delete_all_tables(filename):\n",
    "    for i in list_tables(filename):\n",
    "        conn = sqlite3.connect(filename)\n",
    "        cursor = conn.cursor()\n",
    "        if i != 'General':\n",
    "            cursor.execute(\"DROP TABLE \" + i + \";\")\n",
    "        tables = cursor.fetchall()\n",
    "        conn.close()\n",
    "    return [table[0] for table in tables]\n",
    "\n",
    "#Delete_all_tables(Data_brute)\n",
    "\n",
    "def Delete_one_table(filename, name_table):\n",
    "    conn = sqlite3.connect(filename)\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute(\"DROP TABLE \" + name_table + \";\")\n",
    "    tables = cursor.fetchall()\n",
    "    conn.close()\n",
    "    return [table[0] for table in tables]\n",
    "\n",
    "#Delete_one_table(Data_brute, \"\")\n",
    "\n",
    "Data = 'data/SQL/data.sqlite3'\n",
    "\n",
    "\n",
    "def Delete_data_table(filename, name_table):\n",
    "    conn = sqlite3.connect(filename)\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute(\"DELETE FROM \" + name_table + \";\")\n",
    "    conn.commit() \n",
    "    tables = cursor.fetchall()\n",
    "    conn.close()\n",
    "    return [table[0] for table in tables]\n",
    "\n",
    "#Delete_data_table(Data,\"'General'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create one general table & other tables also\n",
    "\n",
    "entry: chemin de la database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tables in the database: []\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "\n",
    "def Create_tables(filename):\n",
    "    conn = sqlite3.connect(filename)\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute(\"CREATE TABLE General (NAME VARCHAR(50),SURNAME VARCHAR(50),EMAIL VARCHAR(50),CLASS VARCHAR(5),LV1 VARCHAR(50),GRADE_LV1 INT,GROUP_LV1 INT,LV2 VARCHAR(50),GRADE_LV2 INT,GROUP_LV2 VARCHAR(50), EXTRA_TIME BOOLEAN, STATUS VARCHAR(50));\")\n",
    "    tables = cursor.fetchall()\n",
    "    conn.close()\n",
    "    return [table[0] for table in tables]\n",
    "\n",
    "Data = 'data/SQL/data.sqlite3'\n",
    "print(\"Tables in the database:\", Create_tables(Data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tables in the database: []\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "\n",
    "\n",
    "def Create_tables(filename):\n",
    "    conn = sqlite3.connect(filename)\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute(\"CREATE TABLE Teachers  (ID_teacher INT, NAME VARCHAR(50),SURNAME VARCHAR(50),EMAIL VARCHAR(50), SUBJECT VARCHAR(20));\")        # create teacher table\n",
    "    cursor.execute(\"CREATE TABLE Availabilities  (ID_Availability INT, Day VARCHAR(12),Hour VARCHAR(5));\")                                         # create availabilities table\n",
    "    cursor.execute(\"CREATE TABLE Rooms  (ID_teacher INT, NAME VARCHAR(50),SURNAME VARCHAR(50),EMAIL VARCHAR(50), SUBJECT VARCHAR(20));\")           # create Rooms table\n",
    "    cursor.execute(\"CREATE TABLE Summary  (ID_Group VARCHAR(10), ID_teacher INT, ID_Room INT,ID_Availability INT);\")                               # create teacher table\n",
    "    cursor.execute(\"CREATE TABLE Availability_Teachers  (ID_Reacher INT, ID_Availability INT);\")                                                   # create Availability_Teachers table\n",
    "    cursor.execute(\"CREATE TABLE Availability_Rooms  (ID_Room INT, ID_Availability INT);\")                                                         # create Availability_Rooms table\n",
    "    tables = cursor.fetchall()\n",
    "    conn.close()\n",
    "    return [table[0] for table in tables]\n",
    "\n",
    "Data = 'data/SQL/data.sqlite3'\n",
    "print(\"Tables in the database:\", Create_tables(Data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### file general table & other tables also\n",
    "\n",
    "A faire avec les data_student"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for table in the same database\n",
    "import sqlite3\n",
    "\n",
    "def Create_tables(filename):\n",
    "    conn = sqlite3.connect(filename)\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute(\"INSERT INTO General (NAME,SURNAME,EMAIL,CLASS) SELECT colonne_a_copier1, colonne_a_copier2, ..., colonne_a_copierN FROM Sondage_LV2;\")\n",
    "    tables = cursor.fetchall()\n",
    "    conn.close()\n",
    "    return [table[0] for table in tables]\n",
    "\n",
    "Data = 'data/SQL/data.sqlite3'\n",
    "#print(\"Tables in the database:\", Create_tables(Data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "## charger les data eleves from Info_student\n",
    "def copy_data_between_databases(source_db, destination_db):\n",
    "    # Connexion à la base de données source\n",
    "    conn_source = sqlite3.connect(source_db)\n",
    "    cursor_source = conn_source.cursor()\n",
    "    \n",
    "    # Connexion à la base de données destination\n",
    "    conn_destination = sqlite3.connect(destination_db)\n",
    "    cursor_destination = conn_destination.cursor()\n",
    "    \n",
    "    # Exécution de la requête pour copier les données entre les bases de données\n",
    "    cursor_source.execute(\"SELECT Nom, Prénom, mail, Class FROM Info_student;\")\n",
    "    data_to_copy = cursor_source.fetchall()\n",
    "    \n",
    "    for row in data_to_copy:\n",
    "        cursor_destination.execute(\"INSERT INTO General (NAME, SURNAME, EMAIL, CLASS, EXTRA_TIME, STATUS) VALUES (?, ?, ?, ?, FALSE, 'PRESENT' );\", row)\n",
    "    \n",
    "    conn_destination.commit()\n",
    "    \n",
    "    # Fermeture des connexions\n",
    "    conn_source.close()\n",
    "    conn_destination.close()\n",
    "\n",
    "# Exemple d'utilisation\n",
    "source_database = 'data/SQL/data_brute.sqlite3'\n",
    "destination_database = 'data/SQL/data.sqlite3'\n",
    "copy_data_between_databases(source_database, destination_database)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "# a revoir \n",
    "\n",
    "def copy_data_between_databases(source_db, destination_db):\n",
    "    # Connexion à la base de données source\n",
    "    conn_source = sqlite3.connect(source_db)\n",
    "    cursor_source = conn_source.cursor()\n",
    "    \n",
    "    # Connexion à la base de données destination\n",
    "    conn_destination = sqlite3.connect(destination_db)\n",
    "    cursor_destination = conn_destination.cursor()\n",
    "    \n",
    "    # Exécution de la requête pour copier les données entre les bases de données\n",
    "    cursor_source.execute(\"SELECT Nom, Prénom, mail, `Note/10` FROM Anglais;\")\n",
    "    data_to_copy = cursor_source.fetchall()\n",
    "\n",
    "    for row in data_to_copy:\n",
    "        # Check if the data already exists based on name, surname, or email\n",
    "        cursor_destination.execute(\"SELECT COUNT(*) FROM General WHERE NAME = ? AND SURNAME = ? OR EMAIL = ?;\", (row[0], row[1], row[2]))\n",
    "        count = cursor_destination.fetchone()[0]\n",
    "        \n",
    "        if count == 0:\n",
    "            # If data does not exist, insert it into the destination table\n",
    "            #cursor_destination.execute(\"INSERT INTO General (LV1, GRADE_LV1, NAME, SURNAME, EMAIL) VALUES (?, ?, ?, ?, ?);\", ('English', row[3], row[0], row[1], row[2]))\n",
    "            print(row, \"doesn't exist\")\n",
    "        else :\n",
    "            cursor_destination.execute(\"UPDATE General SET LV1=?, GRADE_LV1=? WHERE (NAME = ? AND SURNAME = ?) OR EMAIL = ? ;\", ('English', row[3], row[0], row[1], row[2]))\n",
    "\n",
    "\n",
    "    conn_destination.commit()\n",
    "    \n",
    "    # Fermeture des connexions\n",
    "    conn_source.close()\n",
    "    conn_destination.close()\n",
    "\n",
    "# Exemple d'utilisation\n",
    "source_database = 'data/SQL/data_brute.sqlite3'\n",
    "destination_database = 'data/SQL/data.sqlite3'\n",
    "copy_data_between_databases(source_database, destination_database)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### add forecast\n",
    "\n",
    "entry: nb of forecast, database, table(subject), mu, sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30 forecast add []\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "import numpy as np\n",
    "\n",
    "forecast = 30\n",
    "Data = 'data/SQL/data_brute.sqlite3'\n",
    "table= 'Anglais'\n",
    "\n",
    "def parameters(filename,table_add):\n",
    "    conn = sqlite3.connect(filename)\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute(\"SELECT `Note/10` FROM \" + table_add)\n",
    "    notes = cursor.fetchall()\n",
    "    conn.commit()\n",
    "    conn.close()\n",
    "    numeric_values = [note[0] for note in notes if isinstance(note[0], (int, float))]\n",
    "    mu = np.mean(numeric_values)\n",
    "    sigma = np.var(numeric_values)**0.5\n",
    "    return  mu, sigma\n",
    "\n",
    "def add_forcast(filename,table_add, nb_forecast, mu , sigma ):\n",
    "    conn = sqlite3.connect(filename)\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute(\"SELECT 'Note/10' FROM \" + table_add)\n",
    "    note = cursor.fetchall()\n",
    "    conn.commit()\n",
    "    conn.close()\n",
    "    for i in range(0,nb_forecast):\n",
    "        conn = sqlite3.connect(filename)\n",
    "        cursor = conn.cursor()\n",
    "        valeur_gaussienne = str(np.random.uniform(mu, sigma))\n",
    "        cursor.execute(\"INSERT INTO \" + table_add + \" ('Nom', 'Prénom', 'mail', 'Note/10' ) VALUES ('forecast', 'forecast', 'forecast','\" + valeur_gaussienne + \"')\")\n",
    "        group = cursor.fetchall()\n",
    "        conn.commit()\n",
    "        conn.close()\n",
    "    return group \n",
    "\n",
    "print(forecast,\"forecast add\", add_forcast(Data,table,forecast,parameters(Data, table)[0], parameters(Data, table)[1] ))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create groups\n",
    "\n",
    "entry: database, table (subject), nb by class\n",
    "\n",
    "enregistrer les groupes dans database general"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "\n",
    "def extract_group(filename, table_add):\n",
    "    conn = sqlite3.connect(filename)\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute(\"SELECT * FROM \" + table_add + \" ORDER BY [Note/10] DESC\")\n",
    "    group = cursor.fetchall()\n",
    "    conn.close()\n",
    "    return group\n",
    "\n",
    "\n",
    "Data = 'data/SQL/data_brute.sqlite3'\n",
    "table= 'Anglais'\n",
    "group_data = extract_group(Data, table)\n",
    "\n",
    "\n",
    "def nomber_class(nomber_student, nomber_by_class):\n",
    "    nomber_class = 0\n",
    "    # à expliquer \n",
    "    if (nomber_student % nomber_by_class) > ((nomber_student //nomber_by_class)*(2/3)) :\n",
    "        nomber_class = nomber_student//nomber_by_class + 1\n",
    "    else :\n",
    "        nomber_class = nomber_student//nomber_by_class\n",
    "    return nomber_class\n",
    "\n",
    "nb_student = len(group_data)\n",
    "nb_by_class = 16\n",
    "nb_class = nomber_class(nb_student,nb_by_class)\n",
    "\n",
    "\n",
    "def groups(list_student, number_class):\n",
    "    \n",
    "    # Step 2: Divide the sorted list of students into groups\n",
    "    total_students = len(list_student)\n",
    "    students_per_group = total_students // number_class\n",
    "    extra_students = total_students % number_class\n",
    "    groups = []\n",
    "    start_idx = 0\n",
    "    for i in range(number_class):\n",
    "        end_idx = start_idx + students_per_group\n",
    "        if i < extra_students//2 :\n",
    "            end_idx = end_idx\n",
    "        elif i <  extra_students +  extra_students//2:  # If there are remaining students, distribute them\n",
    "            end_idx += 1\n",
    "        groups.append(list_student[start_idx:end_idx])\n",
    "        start_idx = end_idx\n",
    "    return groups\n",
    "\n",
    "groups = groups(group_data, nb_class)\n",
    "#print(groups)\n",
    "\n",
    "#i = 1\n",
    "#for group in groups:\n",
    "    #print('\\nGroupe\\n', len(group), \"\\n\", group)\n",
    "    #mean = 0\n",
    "    #for student in group:\n",
    "    #    mean =+ mean + float(student[3])\n",
    "    #print(len(group))\n",
    "    #print('Mean', mean/len(group))\n",
    "    #    print('Group ' + str(i), student)\n",
    "    #i+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import sqlite3\n",
    "# a revoir \n",
    "\n",
    "def copy_data_between_databases(groups, destination_db):\n",
    "    \n",
    "    # Connexion à la base de données destination\n",
    "    conn_destination = sqlite3.connect(destination_db)\n",
    "    cursor_destination = conn_destination.cursor()\n",
    "    i = 1\n",
    "    for group in groups :\n",
    "        name_group = 'Group ' + str(i)\n",
    "\n",
    "        for student in group:\n",
    "            # Check if the data already exists based on name, surname, or email\n",
    "            cursor_destination.execute(\"SELECT COUNT(*) FROM General WHERE NAME = ? AND SURNAME = ? OR EMAIL = ?;\", (student[0], student[1], student[2]))\n",
    "            count = cursor_destination.fetchone()[0]\n",
    "            \n",
    "            if count == 0:\n",
    "                # If data does not exist, insert it into the destination table\n",
    "                print(student, \"doesn't exist\")\n",
    "            else :\n",
    "                cursor_destination.execute(\"UPDATE General SET GROUP_LV1=? WHERE (NAME = ? AND SURNAME = ?) OR EMAIL = ?;\", (name_group, student[0], student[1], student[2]))\n",
    "        i +=1\n",
    "\n",
    "    conn_destination.commit()\n",
    "    \n",
    "    # Fermeture des connexions\n",
    "    conn_destination.close()\n",
    "# Exemple d'utilisation\n",
    "destination_database = 'data/SQL/data.sqlite3'\n",
    "copy_data_between_databases(groups, destination_database)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### export the group in PDF \n",
    "\n",
    "entry : liste des groupes + matière du groupe\n",
    "\n",
    "generalisation a finaliser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from reportlab.lib.pagesizes import letter\n",
    "from reportlab.platypus import SimpleDocTemplate, Paragraph, Table, TableStyle, Spacer\n",
    "from reportlab.lib import colors\n",
    "from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle\n",
    "from reportlab.lib.enums import TA_CENTER\n",
    "import os\n",
    "\n",
    "\n",
    "def pdf_maker(groups, langage):\n",
    "    i = 1\n",
    "    styles = getSampleStyleSheet()  \n",
    "\n",
    "    for group in groups:\n",
    "        pdf_path = f\"data/pdf/{langage}_Group_{i}.pdf\"\n",
    "        if os.path.exists(pdf_path):\n",
    "            os.remove(pdf_path)\n",
    "\n",
    "        doc = SimpleDocTemplate(pdf_path, pagesize=letter)\n",
    "        content = []\n",
    "\n",
    "        title = Paragraph(f\"<b>{langage}: Group {i}</b>\", styles[\"Title\"])\n",
    "        content.append(title)\n",
    "        content.append(Spacer(1, 12))  \n",
    "\n",
    "        data = group\n",
    "        table_data = [(\"Name\", \"Surname\", \"Email\", \"Mark\")]\n",
    "        table_data.extend(data)  \n",
    "\n",
    "        table = Table(table_data)\n",
    "        style = TableStyle([('BACKGROUND', (0,0), (-1,0), colors.grey),\n",
    "                            ('TEXTCOLOR', (0,0), (-1,0), colors.whitesmoke),\n",
    "                            ('ALIGN', (0,0), (-1,-1), 'CENTER'),\n",
    "                            ('FONTNAME', (0,0), (-1,0), 'Helvetica-Bold'),\n",
    "                            ('BOTTOMPADDING', (0,0), (-1,0), 12),\n",
    "                            ('BACKGROUND', (0,1), (-1,-1), colors.beige),\n",
    "                            ('GRID', (0,0), (-1,-1), 1, colors.black)])\n",
    "        table.setStyle(style)\n",
    "\n",
    "        content.append(table)\n",
    "\n",
    "        content.append(Spacer(1, 12)) \n",
    "        centered_style = ParagraphStyle(name='Centered', parent=styles['Normal'], alignment=TA_CENTER)\n",
    "\n",
    "        marks = [member[-1] for member in group]  # Supposer que la note est le dernier élément de chaque tuple\n",
    "        mean_mark = sum(marks) / len(marks) if marks else 0\n",
    "\n",
    "        summary = Paragraph(f\"Number of student: {len(group)} ; Mark mean: {mean_mark:.2f}\", centered_style)\n",
    "        content.append(summary)\n",
    "        doc.build(content)\n",
    "        #print(f\"Le fichier PDF '{pdf_path}' a été créé avec succès.\")\n",
    "        i += 1\n",
    "\n",
    "\n",
    "pdf_maker(groups, \"Anglais\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
